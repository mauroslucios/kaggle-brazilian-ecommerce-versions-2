{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mauroslucios/kaggle-brazilian-ecommerce-versions-2/blob/feature%2Fmauro-analytics/analysis_orders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dffeee68-acb2-4b36-ab28-515f1e69087b",
      "metadata": {
        "id": "dffeee68-acb2-4b36-ab28-515f1e69087b"
      },
      "source": [
        "# Analysis orders\n",
        "- Distribuição dos pedidos ao longo do tempo\n",
        "- Correlação entre preço\n",
        "- Frete e avaliações\n",
        "- Análise de geolocalização dos clientes\n",
        "- Previsão de atraso nas entregas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f4b23d6c-0c5b-4850-8055-97b28a812196",
      "metadata": {
        "id": "f4b23d6c-0c5b-4850-8055-97b28a812196"
      },
      "outputs": [],
      "source": [
        "# Creating Session and import libs\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import to_date, count\n",
        "\n",
        "# Create a Spark Session\n",
        "spark = SparkSession.builder.appName(\"Order olist\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d8ebcd8-2742-4377-8820-ae4af62e496a",
      "metadata": {
        "id": "8d8ebcd8-2742-4377-8820-ae4af62e496a"
      },
      "source": [
        "## Analyzing the order over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "49927817-079b-41da-979f-61d8a9b19dea",
      "metadata": {
        "id": "49927817-079b-41da-979f-61d8a9b19dea",
        "outputId": "7c8d8fea-04d4-4dbb-9990-57ae19dda914",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|order_date|order_count|\n",
            "+----------+-----------+\n",
            "|2017-09-11|        180|\n",
            "|2018-08-10|        256|\n",
            "|2018-05-28|        143|\n",
            "|2017-08-11|        141|\n",
            "|2018-06-06|        227|\n",
            "|2018-03-17|        180|\n",
            "|2017-01-06|          4|\n",
            "|2018-08-08|        316|\n",
            "|2018-06-26|        243|\n",
            "|2018-08-11|        188|\n",
            "|2016-10-03|          8|\n",
            "|2018-06-30|        124|\n",
            "|2017-01-27|         62|\n",
            "|2017-02-26|         46|\n",
            "|2017-09-28|        143|\n",
            "|2017-01-24|         40|\n",
            "|2017-09-29|        121|\n",
            "|2017-06-29|        114|\n",
            "|2017-07-31|        148|\n",
            "|2018-03-23|        221|\n",
            "+----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the CSV files into PySpark DataFrames\n",
        "orders = spark.read.csv('data/olist_orders_dataset.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Convert order_purchase_timestamp to date\n",
        "orders = orders.withColumn('order_date', to_date('order_purchase_timestamp'))\n",
        "\n",
        "# Group by order_date and count the number of orders\n",
        "order_distribution = orders.groupBy('order_date').agg(count('order_id').alias('order_count'))\n",
        "\n",
        "# Show the result\n",
        "order_distribution.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ead20c6-b771-4eeb-9063-3cf34a614608",
      "metadata": {
        "id": "4ead20c6-b771-4eeb-9063-3cf34a614608"
      },
      "source": [
        "## Correlation between price, shipping and reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ba981462-b08a-4b9c-9db0-115d18844ea6",
      "metadata": {
        "id": "ba981462-b08a-4b9c-9db0-115d18844ea6",
        "outputId": "e8837559-8fc5-4092-da77-ff657a89f54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'order_items' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-46da3ad1e944>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Join order_items and reviews on order_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mjoined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Select relevant columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'order_items' is not defined"
          ]
        }
      ],
      "source": [
        "# Load the CSV files into PySpark DataFrames\n",
        "order_items = spark.read.csv('data/olist_order_items_dataset.csv', header=True, inferSchema=True)\n",
        "reviews = spark.read.csv('data/olist_order_reviews_dataset.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Join order_items and reviews on order_id\n",
        "joined_df = order_items.join(reviews, order_items.order_id == reviews.order_id, 'left')\n",
        "\n",
        "# Select relevant columns\n",
        "columns = ['price','freight_value','review_score']\n",
        "correlation_df = joined_df.select(columns)\n",
        "\n",
        "# calculation correlation between price, freight_value, and review_score\n",
        "correlation_matrix = correlation_df.toPandas().corr()\n",
        "\n",
        "# Show the correlation matrix\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d61e06f3-ed0c-468d-a38a-730fa9ad9306",
      "metadata": {
        "id": "d61e06f3-ed0c-468d-a38a-730fa9ad9306"
      },
      "source": [
        "## Customer geolocation analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd1bad75-e62f-4a2c-ba17-7b51ba8e8afe",
      "metadata": {
        "id": "cd1bad75-e62f-4a2c-ba17-7b51ba8e8afe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "\n",
        "# Load the CSV files into Pandas DataFrames\n",
        "customers = pd.read_csv('data/olist_customers_dataset.csv')\n",
        "geolocation = pd.read.csv('data/olist_geolocation_dataset.csv')\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (PySpark)",
      "language": "python",
      "name": "pyspark_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}